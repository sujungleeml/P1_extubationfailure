{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석에 필요한 라이브러리\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from pprint import pprint\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras.applications import *\n",
    "#from tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D, Softmax\n",
    "#AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from math import sqrt\n",
    "#import shap\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import random\n",
    "#import shap\n",
    "#import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed\n",
    "seed = 88 #42, 100, 82(XGboost), 88(Light GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_path = 'D:\\projects\\MIMIC3_EXTRACT_R'\n",
    "base_path = '/content/drive/MyDrive/Colab Notebooks/data'\n",
    "df = pd.read_csv(base_path + \"/ventilation_dataset_6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#불필요한 index 삭제\n",
    "data1 = df.drop(df.columns[0], axis = 1)\n",
    "data = data1.rename(columns = {'mbp24':'mbp','vt24':'vt','ve24':'ve', 'hr24':'hr','rr24':'rr', 'mean_pimax24':'pimax','pco24':'pco2'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#성별을 여성(F)=1, 남성(M)=0 으로 변환\n",
    "#data.gender = data.gender.apply(lambda x : mapping_dict_gender[x])\n",
    "#after_mapping_gender\n",
    "#after_mapping_gender = data['gender'].apply(lambda x : mapping_dict_gender[x])\n",
    "#after_mapping_gender\n",
    "\n",
    "mapping_dict_gender = {'F':1,'M':0}\n",
    "data.gender = data.gender.apply(lambda x : mapping_dict_gender[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data = data.reset_index(drop = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv(base_path + '/dataset6_dropna.csv',header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target 과 X 를 분리함.\n",
    "X = data.drop(columns=\"extubation_failure\", axis=1)\n",
    "y = data.extubation_failure\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#StandardScaler: 기본 스케일, 각 피처의 평균을 0, 표준편차를 1로 변환\n",
    "#RobustScaler: 위와 유사하지만 평균 대신 중간값(median)과 일분위, 삼분위값(quartile)을 사용하여 이상치 영향을 최소화\n",
    "#MinMaxScaler: 모든 피처의 최대치와 최소치가 각각 1, 0이 되도록 스케일 조정\n",
    "#Normalizer: 피처(컬럼)이 아니라 row마다 정규화되며, 유클리드 거리가 1이 되도록 데이터를 조정하여 빠르게 학습할 수 있게 함 \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test.loc[y_test ==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set KFold CV\n",
    "kf = KFold(random_state = seed,\n",
    "           n_splits = 5,\n",
    "           shuffle=True,\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimator 정하기\n",
    "estimator = LogisticRegression()\n",
    "estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch가 찾을 parameter를 정의\n",
    "param_grid = {\n",
    "  'penalty' : ['none', 'l2'],\n",
    "  'C' : [0.01, 0.1, 1, 10, 100], #c가 작을수록 제약이 크다..?\n",
    "  'class_weight' : [None, 'balanced'], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grid_search\n",
    "grid_search = GridSearchCV(estimator = estimator,\n",
    "                           param_grid = param_grid,\n",
    "                           cv = kf,\n",
    "                           n_jobs=-1,\n",
    "                           verbose = 2)\n",
    "\n",
    "# fit with(x_train, y_train)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "##{'C': 1, 'class_weight': None, 'penalty': 'l2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from xgboost import plot_importance\n",
    "\n",
    "#Estimator 정하기\n",
    "estimator = XGBClassifier()\n",
    "estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch가 찾을 parameter를 정의\n",
    "param_grid = {\n",
    "    'n_estimators' : [50, 100, 200],\n",
    "    'max_depth' : [4, 5, 6, 7, 8],\n",
    "    'max_features' : [0.7, 0.8, 0.9],\n",
    "    'learning_rate' : [0.001, 0.005, 0.01,0.05, 0.1, 0.5,], #더 넓은 범위도 고려0.0001, 0.0005, 0.001,0.005,\n",
    "    'reg_lambda' : [0.0005,0.001,0.005,0.01,0.05,0.1,0.5] #더 넓은 범위도 고려0.0001, 0.01, 0.05, 0.1, 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grid_search\n",
    "grid_search = GridSearchCV(estimator = estimator,\n",
    "                           param_grid = param_grid,\n",
    "                           cv = kf,\n",
    "                           n_jobs=-1,\n",
    "                           verbose = 2)\n",
    "\n",
    "# fit with(x_train, y_train)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "best_xgb = grid_search.best_estimator_\n",
    "pred_xgb = best_xgb.predict(X_test)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, pred_xgb).ravel()\n",
    "sensitivity = tp/(tp+fn)\n",
    "specificity = tn/(fp+tn)\n",
    "\n",
    "print('precision  :','{0:0.3f}'.format(metrics.precision_score(y_test, pred_xgb)))\n",
    "print('recall(Sensitivity)     :','{0:0.3f}'.format(metrics.recall_score(y_test, pred_xgb))) \n",
    "print('accuracy   :','{0:0.3f}'.format(metrics.accuracy_score(y_test, pred_xgb)))\n",
    "print('sensitivity:', sensitivity)\n",
    "print('specificity:', specificity)\n",
    "print(\"F1 score for XGBoost : %.4f\" % f1_score(y_test, pred_xgb))\n",
    "\n",
    "##{'learning_rate': 0.1, 'max_depth': 7, 'max_features': 0.8, 'n_estimators': 50, 'reg_lambda': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mxgboost\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m XGBClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.6-py3-none-win_amd64.whl (70.9 MB)\n",
      "     ---------------------------------------- 70.9/70.9 MB 7.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\python\\python39\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\python\\python39\\lib\\site-packages (from xgboost) (1.23.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:617: FutureWarning: Pass `objective, use_label_encoder` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "#Estimator 정하기\n",
    "clf =XGBClassifier('max_depth'== 5, 'max_features'== 0.7, 'n_estimators'== 200, 'reg_lambda'== 0.05)\n",
    "#SAVE MODEL\n",
    "with open(\"extfail_xgb_model.pickle\", \"wb\") as f:\n",
    "    pickle.dump(clf, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#target 과 X 를 분리함.\n",
    "X = data.drop(columns=\"extubation_failure\", axis=1)\n",
    "y = data.extubation_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE MODEL\n",
    "with open(\"extfail_xgb_model.pickle\", \"wb\") as f:\n",
    "    pickle.dump(clf, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m s \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(clf)\n\u001b[0;32m      2\u001b[0m clf2 \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mloads(s)\n\u001b[1;32m----> 3\u001b[0m clf2\u001b[39m.\u001b[39mpredict(X[\u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "s = pickle.dumps(clf)\n",
    "clf2 = pickle.loads(s)\n",
    "clf2.predict(X[0:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(clf, 'filename.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25034407fed5d681614dac11a1c0537e8cb49e3a8883c071303eea01322943d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
